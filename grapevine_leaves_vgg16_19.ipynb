{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fd5f8fd-bc9c-452b-9b33-c9542dcabfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16, VGG19\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45d4a30b-dee3-4c12-8869-dfd5c602ce95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define paths\n",
    "dataset_dir = '/Users/ajay/Downloads/Grapevine_Leaves_Image_Dataset'  # Path to your dataset folder\n",
    "base_dir = 'grapevine_split'  # Output folder for split data\n",
    "\n",
    "# Create train and test directories\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "if not os.path.exists(base_dir):\n",
    "    os.makedirs(base_dir)\n",
    "    os.makedirs(train_dir)\n",
    "    os.makedirs(test_dir)\n",
    "\n",
    "# Split each class into train/test\n",
    "for class_name in os.listdir(dataset_dir):\n",
    "    class_dir = os.path.join(dataset_dir, class_name)\n",
    "    if os.path.isdir(class_dir):\n",
    "        # Create class subdirectories in train and test\n",
    "        train_class_dir = os.path.join(train_dir, class_name)\n",
    "        test_class_dir = os.path.join(test_dir, class_name)\n",
    "        os.makedirs(train_class_dir, exist_ok=True)\n",
    "        os.makedirs(test_class_dir, exist_ok=True)\n",
    "\n",
    "        # Get all image files in the class folder\n",
    "        images = [f for f in os.listdir(class_dir) if os.path.isfile(os.path.join(class_dir, f))]\n",
    "        \n",
    "        # Split the images\n",
    "        train_images, test_images = train_test_split(images, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Copy images to train and test folders\n",
    "        for img in train_images:\n",
    "            shutil.copy(os.path.join(class_dir, img), os.path.join(train_class_dir, img))\n",
    "        for img in test_images:\n",
    "            shutil.copy(os.path.join(class_dir, img), os.path.join(test_class_dir, img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be534744-bae5-460b-be6d-e36af4868577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes in training set: ['Dimnit', 'Ak', 'Ala_Idris', 'Nazli', 'Buzgulu']\n",
      "Classes in testing set: ['Dimnit', 'Ak', 'Ala_Idris', 'Nazli', 'Buzgulu']\n"
     ]
    }
   ],
   "source": [
    "print(\"Classes in training set:\", os.listdir(train_dir))\n",
    "print(\"Classes in testing set:\", os.listdir(test_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c03bad09-2395-4d2b-a5b1-149e5b6571a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 images belonging to 5 classes.\n",
      "Found 100 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Data generators\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Load train data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Load test data\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63e32b10-263a-4540-a4ac-60d0e780e157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vgg_model(base_model):\n",
    "    base_model.trainable = False  # Freeze the base model\n",
    "    x = Flatten()(base_model.output)  # Flatten the output of the base model\n",
    "    x = Dense(512, activation='relu')(x)  # Fully connected layer\n",
    "    x = Dropout(0.5)(x)  # Add dropout for regularization\n",
    "    predictions = Dense(train_generator.num_classes, activation='softmax')(x)  # Output layer\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)  # Create the model\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0001),  # Use Adam optimizer\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c2c4a09-4333-4253-baff-03c8c4b826a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training VGG-16 model...\n",
      "Epoch 1/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 5s/step - accuracy: 0.2114 - loss: 2.0369 - val_accuracy: 0.4600 - val_loss: 1.3074\n",
      "Epoch 2/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 5s/step - accuracy: 0.4089 - loss: 1.4002 - val_accuracy: 0.6000 - val_loss: 1.1027\n",
      "Epoch 3/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 5s/step - accuracy: 0.6527 - loss: 0.9907 - val_accuracy: 0.7000 - val_loss: 0.8903\n",
      "Epoch 4/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 5s/step - accuracy: 0.7576 - loss: 0.7496 - val_accuracy: 0.7400 - val_loss: 0.7635\n",
      "Epoch 5/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 5s/step - accuracy: 0.7475 - loss: 0.6720 - val_accuracy: 0.8100 - val_loss: 0.6156\n",
      "Epoch 6/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 5s/step - accuracy: 0.8472 - loss: 0.5067 - val_accuracy: 0.8500 - val_loss: 0.5586\n",
      "Epoch 7/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 5s/step - accuracy: 0.8683 - loss: 0.4662 - val_accuracy: 0.8500 - val_loss: 0.5225\n",
      "Epoch 8/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 5s/step - accuracy: 0.8656 - loss: 0.4280 - val_accuracy: 0.8700 - val_loss: 0.4896\n",
      "Epoch 9/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 6s/step - accuracy: 0.9102 - loss: 0.3506 - val_accuracy: 0.8100 - val_loss: 0.5534\n",
      "Epoch 10/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 7s/step - accuracy: 0.8879 - loss: 0.3684 - val_accuracy: 0.8300 - val_loss: 0.4901\n",
      "Epoch 11/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 4s/step - accuracy: 0.9452 - loss: 0.2618 - val_accuracy: 0.8500 - val_loss: 0.4299\n",
      "Epoch 12/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 7s/step - accuracy: 0.9312 - loss: 0.2569 - val_accuracy: 0.8700 - val_loss: 0.4126\n",
      "Epoch 13/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 6s/step - accuracy: 0.9780 - loss: 0.1857 - val_accuracy: 0.8700 - val_loss: 0.4203\n",
      "Epoch 14/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 6s/step - accuracy: 0.9396 - loss: 0.2475 - val_accuracy: 0.8500 - val_loss: 0.4086\n",
      "Epoch 15/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 6s/step - accuracy: 0.9682 - loss: 0.1906 - val_accuracy: 0.8600 - val_loss: 0.3969\n",
      "Epoch 16/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 6s/step - accuracy: 0.9688 - loss: 0.1922 - val_accuracy: 0.8600 - val_loss: 0.3916\n",
      "Epoch 17/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 6s/step - accuracy: 0.9916 - loss: 0.1582 - val_accuracy: 0.8200 - val_loss: 0.3887\n",
      "Epoch 18/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 6s/step - accuracy: 0.9795 - loss: 0.1470 - val_accuracy: 0.8700 - val_loss: 0.3590\n",
      "Epoch 19/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 6s/step - accuracy: 0.9815 - loss: 0.1345 - val_accuracy: 0.8500 - val_loss: 0.3930\n",
      "Epoch 20/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 6s/step - accuracy: 0.9915 - loss: 0.1205 - val_accuracy: 0.8500 - val_loss: 0.3849\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train VGG-16 model\n",
    "vgg16_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "vgg16_model = create_vgg_model(vgg16_base)\n",
    "\n",
    "print(\"Training VGG-16 model...\")\n",
    "vgg16_history = vgg16_model.fit(\n",
    "    train_generator,\n",
    "    validation_data=test_generator,\n",
    "    epochs=20, \n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3e2c58b-dd19-4f24-8048-ca6ae221756f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training VGG-19 model...\n",
      "Epoch 1/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 7s/step - accuracy: 0.2283 - loss: 2.1903 - val_accuracy: 0.4400 - val_loss: 1.5709\n",
      "Epoch 2/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 7s/step - accuracy: 0.3739 - loss: 1.4678 - val_accuracy: 0.6600 - val_loss: 1.0736\n",
      "Epoch 3/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 7s/step - accuracy: 0.5448 - loss: 1.1139 - val_accuracy: 0.6900 - val_loss: 0.9317\n",
      "Epoch 4/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 8s/step - accuracy: 0.6624 - loss: 0.8823 - val_accuracy: 0.7600 - val_loss: 0.7725\n",
      "Epoch 5/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 7s/step - accuracy: 0.7518 - loss: 0.7124 - val_accuracy: 0.7800 - val_loss: 0.7046\n",
      "Epoch 6/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 7s/step - accuracy: 0.8432 - loss: 0.6090 - val_accuracy: 0.8200 - val_loss: 0.6467\n",
      "Epoch 7/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 7s/step - accuracy: 0.8417 - loss: 0.5691 - val_accuracy: 0.7800 - val_loss: 0.6234\n",
      "Epoch 8/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 7s/step - accuracy: 0.8786 - loss: 0.5228 - val_accuracy: 0.8000 - val_loss: 0.5999\n",
      "Epoch 9/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 7s/step - accuracy: 0.8757 - loss: 0.4684 - val_accuracy: 0.8200 - val_loss: 0.5552\n",
      "Epoch 10/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 7s/step - accuracy: 0.9257 - loss: 0.3622 - val_accuracy: 0.8400 - val_loss: 0.5204\n",
      "Epoch 11/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 7s/step - accuracy: 0.8927 - loss: 0.3909 - val_accuracy: 0.8100 - val_loss: 0.5444\n",
      "Epoch 12/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 8s/step - accuracy: 0.8903 - loss: 0.3933 - val_accuracy: 0.8200 - val_loss: 0.5036\n",
      "Epoch 13/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 8s/step - accuracy: 0.9010 - loss: 0.3420 - val_accuracy: 0.8300 - val_loss: 0.4823\n",
      "Epoch 14/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 8s/step - accuracy: 0.9141 - loss: 0.3138 - val_accuracy: 0.8500 - val_loss: 0.4789\n",
      "Epoch 15/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 8s/step - accuracy: 0.9725 - loss: 0.2555 - val_accuracy: 0.8300 - val_loss: 0.4398\n",
      "Epoch 16/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 8s/step - accuracy: 0.9616 - loss: 0.2285 - val_accuracy: 0.8500 - val_loss: 0.4231\n",
      "Epoch 17/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 8s/step - accuracy: 0.9666 - loss: 0.2065 - val_accuracy: 0.8500 - val_loss: 0.4068\n",
      "Epoch 18/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 8s/step - accuracy: 0.9423 - loss: 0.2151 - val_accuracy: 0.8400 - val_loss: 0.4680\n",
      "Epoch 19/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 8s/step - accuracy: 0.9548 - loss: 0.2139 - val_accuracy: 0.8600 - val_loss: 0.4088\n",
      "Epoch 20/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 8s/step - accuracy: 0.9769 - loss: 0.1823 - val_accuracy: 0.8400 - val_loss: 0.3930\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train VGG-19 model\n",
    "vgg19_base = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "vgg19_model = create_vgg_model(vgg19_base)\n",
    "\n",
    "print(\"Training VGG-19 model...\")\n",
    "vgg19_history = vgg19_model.fit(\n",
    "    train_generator,\n",
    "    validation_data=test_generator,\n",
    "    epochs=20, \n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "afb868a8-aa0f-400b-a175-0da85920ee9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating VGG-16 model...\n",
      "VGG-16: Accuracy = 85.00%, Loss = 0.3849\n",
      "Evaluating VGG-19 model...\n",
      "VGG-19: Accuracy = 84.00%, Loss = 0.3930\n",
      "Models saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate both models\n",
    "print(\"Evaluating VGG-16 model...\")\n",
    "vgg16_eval = vgg16_model.evaluate(test_generator, verbose=0)\n",
    "print(f\"VGG-16: Accuracy = {vgg16_eval[1]*100:.2f}%, Loss = {vgg16_eval[0]:.4f}\")\n",
    "\n",
    "print(\"Evaluating VGG-19 model...\")\n",
    "vgg19_eval = vgg19_model.evaluate(test_generator, verbose=0)\n",
    "print(f\"VGG-19: Accuracy = {vgg19_eval[1]*100:.2f}%, Loss = {vgg19_eval[0]:.4f}\")\n",
    "\n",
    "# Save the trained models\n",
    "vgg16_model.save('vgg16_grapevine_model.keras')\n",
    "vgg19_model.save('vgg19_grapevine_model.keras')\n",
    "\n",
    "print(\"Models saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad8a109-9e85-4f7f-8c6c-5a43ff4e66cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
